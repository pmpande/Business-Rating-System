{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import random\n",
    "import nltk\n",
    "from nltk.corpus import sentiwordnet as swn\n",
    "from nltk.stem import *\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def removeStopWords(text):\n",
    "    #stopwords = nltk.corpus.stopwords.words('english')\n",
    "    stopwords = ['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'she', 'her', 'hers', 'herself', 'it', 'its', 'itself', 'they'\n",
    "                 , 'them', 'their', 'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that'\n",
    "                 , 'these', 'those', 'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', \n",
    "                 'has', 'had', 'having', 'do', 'does', 'did', 'doing', 'a', 'an', 'the', 'and','to']\n",
    "    #print(stopwords)\n",
    "    #stopwords.remove('not')\n",
    "    content = [w for w in text if w.lower() not in stopwords]\n",
    "    return content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'she', 'her', 'hers', 'herself', 'it', 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', 'these', 'those', 'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', 'did', 'doing', 'a', 'an', 'the', 'and', 'to']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['not', 'never', 'permit', 'us', 'obtain', 'refuse', 'permit']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = nltk.word_tokenize(\"They did not never to permit us to obtain the refuse permit\")\n",
    "filteredText = removeStopWords(text)\n",
    "filteredText"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open(\"/u/ggabra/Search Project/yelp_academic_dataset_review.json\") as f:\n",
    "    data = pd.DataFrame(json.loads(line) for line in f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rows = random.sample(range(0,len(data)-1),268500)\n",
    "testData = data.iloc[rows,[3,4]].copy() \n",
    "testData=testData.reset_index(drop=True)\n",
    "trainData = data.drop(rows)\n",
    "trainData=trainData.reset_index(drop=True)\n",
    "trainData.drop(trainData.columns[[0,1,2,5,6,7]], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>stars</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4</td>\n",
       "      <td>Mr Hoagie is an institution. Walking in, it do...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   stars                                               text\n",
       "0      4  Mr Hoagie is an institution. Walking in, it do..."
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sampleData = trainData[:10000]\n",
    "sampleData.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "bigList=[]\n",
    "train_label=[]\n",
    "JJRB = set(['JJ', 'RB','JJR'])\n",
    "for index,row in sampleData.iterrows():\n",
    "    #lst = []\n",
    "    wordList = []\n",
    "    tokens = removeStopWords(nltk.word_tokenize(row[1]))\n",
    "    tags = nltk.pos_tag(tokens)\n",
    "    #print(tags)\n",
    "    #for tag in tags:\n",
    "    #    if tag[1] == 'JJ' or tag[1] == 'RB': \n",
    "    #        wordList.append(tag[0])\n",
    "    #wordString = ' '.join([ tag[0] for tag in tags if tag[1] in JJRB ]).lower()        \n",
    "    #bigList.append(wordString)\n",
    "    bigList.append(' '.join([ tag[0] for tag in tags if tag[1] in JJRB ]).lower())\n",
    "    train_label.append(row[0])    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('nice enough enough good enough absolutely wrong not full great back not wow great just good enough',\n",
       " 5)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bigList[50],train_label[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sampleTestData = testData[:1000]\n",
    "\n",
    "testList=[]\n",
    "test_label=[]\n",
    "JJRB = set(['JJ', 'RB',' JJR'])\n",
    "for index,row in sampleTestData.iterrows():\n",
    "    #lst = []\n",
    "    wordList = []\n",
    "    tokens = removeStopWords(nltk.word_tokenize(row[1]))\n",
    "    tags = nltk.pos_tag(tokens)\n",
    "    #print(tags)\n",
    "    #for tag in tags:\n",
    "    #    if tag[1] == 'JJ' or tag[1] == 'RB': \n",
    "    #        wordList.append(tag[0])\n",
    "    #wordString = ' '.join([ tag[0] for tag in tags if tag[1] in JJRB ]).lower()        \n",
    "    #bigList.append(wordString)\n",
    "    testList.append(' '.join([ tag[0] for tag in tags if tag[1] in JJRB ]).lower())\n",
    "    test_label.append(row[0]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('the', 'DT'), ('drive-thru', 'NN')]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "text = nltk.word_tokenize(\"the drive-thru\")\n",
    "tagWordList = nltk.pos_tag(text)\n",
    "tagWordList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.linear_model import SGDClassifier, LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.svm import SVC\n",
    "import numpy\n",
    "text_clf = Pipeline([('vect', CountVectorizer(ngram_range=[1,2])),\n",
    "                      ('tfidf', TfidfTransformer()),\n",
    "                      ('clf', SGDClassifier(loss='hinge', penalty='l2',\n",
    "                                            alpha=1e-3, n_iter=5, random_state=42))     #change classifier names here\n",
    " ])\n",
    "_ = text_clf.fit(bigList, train_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.54400000000000004"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted_label = text_clf.predict(testList)\n",
    "numpy.mean(predicted_label == test_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.2099586769803339"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "from math import sqrt\n",
    "sqrt(mean_squared_error(test_label, predicted_label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 403,   13,   40,   25,  125],\n",
       "       [ 152,   38,   63,   51,   85],\n",
       "       [  85,   26,  127,  182,  161],\n",
       "       [  47,   12,   92,  356,  815],\n",
       "       [  63,    7,   40,  187, 1805]])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "#print(metrics.classification_report(twenty_test.target, predicted, target_names=twenty_test.target_names))\n",
    "metrics.confusion_matrix(test_label, predicted_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.54      0.67      0.59       606\n",
      "          2       0.40      0.10      0.16       389\n",
      "          3       0.35      0.22      0.27       581\n",
      "          4       0.44      0.27      0.34      1322\n",
      "          5       0.60      0.86      0.71      2102\n",
      "\n",
      "avg / total       0.51      0.55      0.50      5000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "targetNames = []\n",
    "targetNames.append('1')\n",
    "targetNames.append('2')\n",
    "targetNames.append('3')\n",
    "targetNames.append('4')\n",
    "targetNames.append('5')\n",
    "print(metrics.classification_report(test_label, predicted_label,\n",
    "   target_names=targetNames))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print('hi')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}

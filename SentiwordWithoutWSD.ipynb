{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json as js\n",
    "\n",
    "with open(\"/u/pmpande/author_profiling/training_file.json\") as f:\n",
    "    data = pd.DataFrame(js.loads(line) for line in f)\n",
    "f.close()\n",
    "\n",
    "with open(\"/u/pmpande/author_profiling/testing_file.json\") as ft:\n",
    "    data_test = pd.DataFrame(js.loads(line) for line in ft)\n",
    "ft.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running Iteration 0...\n",
      "Running Iteration 1...\n",
      "Running Iteration 2...\n",
      "Running Iteration 3...\n",
      "Running Iteration 4...\n",
      "Running Iteration 5...\n",
      "Running Iteration 6...\n",
      "Running Iteration 7...\n",
      "Running Iteration 8...\n",
      "Running Iteration 9...\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "from math import sqrt\n",
    "import numpy as np\n",
    "\n",
    "import nltk\n",
    "from nltk.corpus import sentiwordnet as swn\n",
    "from nltk.corpus import wordnet as wn\n",
    "from nltk.wsd import lesk\n",
    "from nltk.stem import *\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import SGDClassifier, LogisticRegression\n",
    "from sklearn import tree\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "acc1 = []\n",
    "acc2 = []\n",
    "acc3 = []\n",
    "acc4 = []\n",
    "rmse1 = []\n",
    "rmse2 = []\n",
    "rmse3 = []\n",
    "rmse4 = []\n",
    "\n",
    "for i in range(10):\n",
    "    print(\"Running Iteration \" + str(i) + \"...\")\n",
    "    #Get Random 50,000 records for training\n",
    "    rand_train = random.sample(range(0,len(data)),10000)\n",
    "    train = data.iloc[rand_train].copy()\n",
    "\n",
    "    #Get Random 5,000 records for testing\n",
    "    rand_test = random.sample(range(0,len(data_test)),1000)\n",
    "    test = data_test.iloc[rand_test].copy()\n",
    "    \n",
    "    corpus = []\n",
    "    truth = []\n",
    "    for row in train.iterrows():\n",
    "        corpus.append(row[1]['text'])\n",
    "        truth.append(row[1]['stars'])     \n",
    "\n",
    "    corpus_test = []\n",
    "    truth_test = []\n",
    "    for row in test.iterrows():\n",
    "        corpus_test.append(row[1]['text'])\n",
    "        truth_test.append(row[1]['stars'])\n",
    "        \n",
    "    new = []\n",
    "    count = 0\n",
    "    for row in corpus:\n",
    "        lst = []\n",
    "        tokens = nltk.word_tokenize(row)\n",
    "        tags = nltk.pos_tag(tokens)\n",
    "        for tag in tags:\n",
    "            if tag[1] == 'JJ':\n",
    "                temp = (tag[0],'a')\n",
    "                lst.append(temp)\n",
    "            elif tag[1] == 'RB': \n",
    "                temp = (tag[0],'r')\n",
    "                lst.append(temp)\n",
    "        pos = 0\n",
    "        neg = 0\n",
    "        score = []\n",
    "        for word in lst:\n",
    "            if len(list(swn.senti_synsets(word[0],word[1]))) != 0:\n",
    "                pos += (list(swn.senti_synsets(word[0],word[1]))[0]).pos_score()\n",
    "                neg += (list(swn.senti_synsets(word[0],word[1]))[0]).neg_score()\n",
    "        total = pos+neg\n",
    "        if total == 0:\n",
    "            score.append(0)\n",
    "            score.append(0)\n",
    "        else:\n",
    "            score.append(pos/total)\n",
    "            score.append(neg/total)\n",
    "        new.append(score)\n",
    "        \n",
    "    new_test = []\n",
    "    for row in corpus_test:\n",
    "        lst = []\n",
    "        tokens = nltk.word_tokenize(row)\n",
    "        tags = nltk.pos_tag(tokens)\n",
    "        for tag in tags:\n",
    "            if tag[1] == 'JJ':\n",
    "                temp = (tag[0],'a')\n",
    "                lst.append(temp)\n",
    "            elif tag[1] == 'RB': \n",
    "                temp = (tag[0],'r')\n",
    "                lst.append(temp)\n",
    "        pos = 0\n",
    "        neg = 0\n",
    "        score = []\n",
    "        for word in lst:\n",
    "            if len(list(swn.senti_synsets(word[0],word[1]))) != 0:\n",
    "                pos += (list(swn.senti_synsets(word[0],word[1]))[0]).pos_score()\n",
    "                neg += (list(swn.senti_synsets(word[0],word[1]))[0]).neg_score()\n",
    "        total = pos+neg\n",
    "        if total == 0:\n",
    "            score.append(0)\n",
    "            score.append(0)\n",
    "        else:\n",
    "            score.append(pos/total)\n",
    "            score.append(neg/total)\n",
    "        new_test.append(score)\n",
    "        \n",
    "    train_x = np.array(new)\n",
    "    test_x = np.array(new_test)\n",
    "        \n",
    "    clf = MultinomialNB().fit(train_x,truth)\n",
    "    clf1 = SGDClassifier(loss='hinge', penalty='l2', alpha=1e-3, n_iter=5, random_state=42).fit(train_x,truth)\n",
    "    clf2 = tree.DecisionTreeClassifier().fit(train_x,truth)\n",
    "    clf3 = LogisticRegression(solver='newton-cg', multi_class='multinomial').fit(train_x,truth)\n",
    "\n",
    "    predicted = clf.predict(test_x)\n",
    "    acc1.append(np.mean(predicted == truth_test)) \n",
    "\n",
    "    predicted1 = clf1.predict(test_x)\n",
    "    acc2.append(np.mean(predicted1 == truth_test))\n",
    "\n",
    "    predicted2 = clf2.predict(test_x)\n",
    "    acc3.append(np.mean(predicted2 == truth_test))\n",
    "\n",
    "    predicted3 = clf3.predict(test_x)\n",
    "    acc4.append(np.mean(predicted3 == truth_test)) \n",
    "\n",
    "    #targetNames = ['1','2','3','4','5']\n",
    "    #print(metrics.classification_report(truth_test, predicted,target_names=targetNames))\n",
    "    #print(metrics.classification_report(truth_test, predicted1,target_names=targetNames))\n",
    "    #print(metrics.classification_report(truth_test, predicted2,target_names=targetNames))\n",
    "    #print(metrics.classification_report(truth_test, predicted3,target_names=targetNames))\n",
    "    \n",
    "    #print(metrics.confusion_matrix(truth_test, predicted))\n",
    "    #print(\"---------------------------------\")\n",
    "    #print(metrics.confusion_matrix(truth_test, predicted1))\n",
    "    #print(\"---------------------------------\")\n",
    "    #print(metrics.confusion_matrix(truth_test, predicted2))\n",
    "    #print(\"---------------------------------\")\n",
    "    #print(metrics.confusion_matrix(truth_test, predicted3))\n",
    "\n",
    "    rmse1.append(sqrt(mean_squared_error(truth_test, predicted)))\n",
    "    rmse2.append(sqrt(mean_squared_error(truth_test, predicted1)))\n",
    "    rmse3.append(sqrt(mean_squared_error(truth_test, predicted2)))\n",
    "    rmse4.append(sqrt(mean_squared_error(truth_test, predicted3)))\n",
    "    \n",
    "    del train\n",
    "    del test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average accuracy 1: 0.4232\n",
      "Average accuracy 2: 0.4222\n",
      "Average accuracy 3: 0.4102\n",
      "Average accuracy 4: 0.4501\n",
      "Average rmse 1: 1.8785850068325654\n",
      "Average rmse 2: 1.6922369058116793\n",
      "Average rmse 3: 1.7053672017600323\n",
      "Average rmse 4: 1.7608033637464122\n"
     ]
    }
   ],
   "source": [
    "accf1 = 0\n",
    "accf2 = 0\n",
    "accf3 = 0\n",
    "accf4 = 0\n",
    "rmsef1 = 0\n",
    "rmsef2 = 0\n",
    "rmsef3 = 0\n",
    "rmsef4 = 0\n",
    "for i in range(10):\n",
    "    accf1 += acc1[i]\n",
    "    accf2 += acc2[i]\n",
    "    accf3 += acc3[i]\n",
    "    accf4 += acc4[i]\n",
    "    \n",
    "    rmsef1 += rmse1[i]\n",
    "    rmsef2 += rmse2[i]\n",
    "    rmsef3 += rmse3[i]\n",
    "    rmsef4 += rmse4[i]\n",
    "    \n",
    "print(\"Average accuracy 1: \" + str(accf1/10))\n",
    "print(\"Average accuracy 2: \" + str(accf2/10))\n",
    "print(\"Average accuracy 3: \" + str(accf3/10))\n",
    "print(\"Average accuracy 4: \" + str(accf4/10))\n",
    "   \n",
    "print(\"Average rmse 1: \" + str(rmsef1/10))\n",
    "print(\"Average rmse 2: \" + str(rmsef2/10))\n",
    "print(\"Average rmse 3: \" + str(rmsef3/10))\n",
    "print(\"Average rmse 4: \" + str(rmsef4/10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
